# OVOS EnMS Voice Assistant - Docker Compose
# Headless deployment for integration with EnMS system

services:
  ovos:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ovos-enms
    restart: unless-stopped
    ports:
      - "5000:5000"
    environment:
      - ENMS_API_URL=${ENMS_API_URL:-http://host.docker.internal:8001/api/v1}
      - OVOS_BRIDGE_PORT=5000
      - OVOS_TTS_ENABLED=${OVOS_TTS_ENABLED:-true}
      - OVOS_TTS_ENGINE=${OVOS_TTS_ENGINE:-edge-tts}
      - OVOS_TTS_VOICE=${OVOS_TTS_VOICE:-en-US-GuyNeural}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LLM_MODEL_PATH=/models/Qwen_Qwen3-1.7B-Q4_K_M.gguf
    volumes:
      # Mount LLM model from host (download separately)
      - ${LLM_MODEL_DIR:-./models}:/models:ro
      # Optional: Mount config for customization
      - ./enms-ovos-skill/settings.json:/app/settings.json:ro
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - enms-network
    # For accessing localhost:8001 from container
    extra_hosts:
      - "host.docker.internal:host-gateway"

networks:
  enms-network:
    external: true
    name: enms-network
