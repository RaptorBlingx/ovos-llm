# OVOS EnMS Voice Assistant - Environment Configuration
# Copy this file to .env and customize for your deployment

# ============================================================================
# EnMS API Configuration
# ============================================================================

# EnMS API URL - the backend this voice assistant connects to
# For Docker: use host.docker.internal to reach host machine's localhost
# For same Docker network: use service name (e.g., http://enms:8001/api/v1)
ENMS_API_URL=http://host.docker.internal:8001/api/v1

# ============================================================================
# LLM Model Configuration
# ============================================================================

# Path to LLM model directory on host (mounted as /models in container)
# Download model: huggingface-cli download Qwen/Qwen3-1.7B-GGUF Qwen_Qwen3-1.7B-Q4_K_M.gguf --local-dir ./models
LLM_MODEL_DIR=./models

# ============================================================================
# TTS (Text-to-Speech) Configuration
# ============================================================================

# Enable/disable TTS audio responses
OVOS_TTS_ENABLED=true

# TTS engine: edge-tts (cloud, fast), espeak (local, fallback)
OVOS_TTS_ENGINE=edge-tts

# TTS voice (edge-tts voices)
# Options: en-US-GuyNeural, en-US-JennyNeural, en-GB-RyanNeural
OVOS_TTS_VOICE=en-US-GuyNeural

# ============================================================================
# Logging & Debug
# ============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# ============================================================================
# Docker Network Configuration
# ============================================================================

# Name of existing EnMS Docker network to join
# Run: docker network ls | grep enms to find the network name
ENMS_NETWORK=enms_default
